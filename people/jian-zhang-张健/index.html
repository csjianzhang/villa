<!DOCTYPE html><html lang="en-us" >

<head>

  <meta charset="utf-8">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <meta name="generator" content="Source Themes Academic 4.8.0">

  

  
  

  
  
  
  
  
    
    
    
  
  

  <meta name="author" content="Jian Zhang (张健)">

  
  
  
    
  
  <meta name="description" content="Assistant Professor, Ph. D. Supervisor">

  
  <link rel="alternate" hreflang="en-us" href="/people/jian-zhang-%E5%BC%A0%E5%81%A5/">

  







  




  
  
    <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
  

  
  
  
  <meta name="theme-color" content="#3f51b5">
  

  
  

  
  
  
  
    
    
      <link rel="stylesheet" href="https://cdn.bootcdn.net/ajax/libs/academicons/1.8.6/css/academicons.min.css" integrity="sha256-uFVgMKfistnJAfoCUQigIl+JfUaP47GrRKjf6CTPVmw=" crossorigin="anonymous">
    
    <link rel="stylesheet" href="https://cdn.bootcdn.net/ajax/libs/font-awesome/5.14.0/css/all.min.css" integrity="sha256-FMvZuGapsJLjouA6k7Eo2lusoAX9i0ShlWFG6qt7SLc=" crossorigin="anonymous">
    <link rel="stylesheet" href="https://cdn.bootcdn.net/ajax/libs/fancybox/3.5.7/jquery.fancybox.min.css" integrity="sha256-Vzbj7sDDS/woiFS3uNKo8eIuni59rjyNGtXfstRzStA=" crossorigin="anonymous">

    
    
    
      
    
    
      
      
        
          <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/10.1.2/styles/github.min.css" crossorigin="anonymous" title="hl-light">
          <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/10.1.2/styles/dracula.min.css" crossorigin="anonymous" title="hl-dark" disabled>
        
      
    

    
    <link rel="stylesheet" href="https://cdn.bootcdn.net/ajax/libs/leaflet/1.5.1/leaflet.css" integrity="sha256-SHMGCYmST46SoyGgo4YR/9AlK1vf3ff84Aq9yK4hdqM=" crossorigin="anonymous">
    

    

    
    
      

      
      

      
    
      

      
      

      
    
      

      
      

      
    
      

      
      

      
    
      

      
      

      
    
      

      
      

      
    
      

      
      

      
    
      

      
      

      
    
      

      
      

      
    
      

      
      

      
    
      

      
      

      
    
      

      
      

      
        <script src="https://cdn.bootcdn.net/ajax/libs/lazysizes/5.1.2/lazysizes.min.js" integrity="sha256-Md1qLToewPeKjfAHU1zyPwOutccPAm5tahnaw7Osw0A=" crossorigin="anonymous" async></script>
      
    
      

      
      

      
    
      

      
      

      
    
      

      
      
        
      

      
    
      

      
      

      
    
      

      
      

      
    

  

  
  
  
    
      
      
      <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Montserrat:400,700%7CRoboto:400,400italic,700%7CRoboto+Mono&display=swap">
    
  

  
  
  
  
  <link rel="stylesheet" href="/css/academic.css">

  




  


  
  

  
  <link rel="alternate" href="/people/jian-zhang-%E5%BC%A0%E5%81%A5/index.xml" type="application/rss+xml" title="VILLA">
  

  <link rel="manifest" href="/index.webmanifest">
  <link rel="icon" type="image/png" href="/images/icon_hu1c69c5c7f1761a6e16ae9a9b731ec3dc_270566_32x32_fill_lanczos_center_2.png">
  <link rel="apple-touch-icon" type="image/png" href="/images/icon_hu1c69c5c7f1761a6e16ae9a9b731ec3dc_270566_192x192_fill_lanczos_center_2.png">

  <link rel="canonical" href="/people/jian-zhang-%E5%BC%A0%E5%81%A5/">

  
  
  
  
  
  
  
    
    
  
  
  <meta property="twitter:card" content="summary">
  
  <meta property="og:site_name" content="VILLA">
  <meta property="og:url" content="/people/jian-zhang-%E5%BC%A0%E5%81%A5/">
  <meta property="og:title" content="Jian Zhang (张健) | VILLA">
  <meta property="og:description" content="Assistant Professor, Ph. D. Supervisor"><meta property="og:image" content="/images/logo_hu16b66c2cf49f7857852328888cf4bf88_15211_300x300_fit_lanczos_2.png">
  <meta property="twitter:image" content="/images/logo_hu16b66c2cf49f7857852328888cf4bf88_15211_300x300_fit_lanczos_2.png"><meta property="og:locale" content="en-us">
  
    <meta property="og:updated_time" content="2024-02-29T00:00:00&#43;00:00">
  

  




  


  





  <title>Jian Zhang (张健) | VILLA</title>

</head>


<body id="top" data-spy="scroll" data-offset="70" data-target="#TableOfContents" class=" ">

  
  
  
  
    <script>const isSiteThemeDark = false;</script>
  
  
  <script src="/js/load-theme.js"></script>

  <aside class="search-results" id="search">
  <div class="container">
    <section class="search-header">

      <div class="row no-gutters justify-content-between mb-3">
        <div class="col-6">
          <h1>Search</h1>
        </div>
        <div class="col-6 col-search-close">
          <a class="js-search" href="#"><i class="fas fa-times-circle text-muted" aria-hidden="true"></i></a>
        </div>
      </div>

      <div id="search-box">
        
        
        
      </div>

    </section>
    <section class="section-search-results">

      <div id="search-hits">
        
      </div>

    </section>
  </div>
</aside>


  











  


<nav class="navbar navbar-expand-lg navbar-light compensate-for-scrollbar" id="navbar-main">
  <div class="container">

    
    <div class="d-none d-lg-inline-flex">
      <a class="navbar-brand" href="/"><img src="/images/logo_hu16b66c2cf49f7857852328888cf4bf88_15211_0x70_resize_lanczos_2.png" alt="VILLA"></a>
    </div>
    

    
    <button type="button" class="navbar-toggler" data-toggle="collapse"
            data-target="#navbar-content" aria-controls="navbar" aria-expanded="false" aria-label="Toggle navigation">
    <span><i class="fas fa-bars"></i></span>
    </button>
    

    
    <div class="navbar-brand-mobile-wrapper d-inline-flex d-lg-none">
      <a class="navbar-brand" href="/"><img src="/images/logo_hu16b66c2cf49f7857852328888cf4bf88_15211_0x70_resize_lanczos_2.png" alt="VILLA"></a>
    </div>
    

    
    
    <div class="navbar-collapse main-menu-item collapse justify-content-end" id="navbar-content">

      
      <ul class="navbar-nav d-md-inline-flex">
        

        

        
        
        

        

        
        
        
        

        
          
            
            
          
          
            
            
            
              
            
            
          
        

        <li class="nav-item">
          <a class="nav-link " href="/#top"><span>Home</span></a>
        </li>

        
        

        

        
        
        
          
        

        

        
        
        
        

        
          
            
            
          
          
            
            
            
              
            
            
          
        

        <li class="nav-item">
          <a class="nav-link " href="/#people"><span>Team</span></a>
        </li>

        
        

        

        
        
        
          
        

        

        
        
        
        

        
          
            
            
          
          
            
            
            
              
            
            
          
        

        <li class="nav-item">
          <a class="nav-link " href="/#news"><span>News</span></a>
        </li>

        
        

        

        
        
        

        

        
        
        
        

        
          
            
            
          
          
        

        <li class="nav-item">
          <a class="nav-link " href="/pub"><span>Publications</span></a>
        </li>

        
        

        

        
        
        
          
        

        

        
        
        
        

        
          
            
            
          
          
            
            
            
              
            
            
          
        

        <li class="nav-item">
          <a class="nav-link " href="/#openings"><span>Openings</span></a>
        </li>

        
        

        

        
        
        
          
        

        

        
        
        
        

        
          
            
            
          
          
            
            
            
              
            
            
          
        

        <li class="nav-item">
          <a class="nav-link " href="/#contact"><span>Contact</span></a>
        </li>

        
        

      

        
      </ul>
    </div>

    <ul class="nav-icons navbar-nav flex-row ml-auto d-flex pl-md-2">
      
      

      
      

      

    </ul>

  </div>
</nav>



  




<section id="profile-page" class="pt-5">
  <div class="container">
    
    
      
      
      
      




  










<div class="row">
  <div class="col-12 col-lg-4">
    <div id="profile">

      
      
      <img class="avatar avatar-square" src="/people/jian-zhang-%E5%BC%A0%E5%81%A5/avatar_huf2de7b89ca0dc6035c2478c83d3b7153_304316_270x270_fill_q90_lanczos_center.jpg" alt="Jian Zhang (张健)">
      

      <div class="portrait-title">
        <h2>Jian Zhang (张健)</h2>
        <h3>Assistant Professor, Ph. D. Supervisor</h3>

        
        <h3>
          <a href="http://www.ece.pku.edu.cn" target="_blank" rel="noopener">
          <span>School of Electronic and Computer Engineering</span>
          </a>
        </h3>
        
        <h3>
          <a href="http://www.pkusz.edu.cn" target="_blank" rel="noopener">
          <span>Shenzhen Graduate School</span>
          </a>
        </h3>
        
        <h3>
          <a href="https://www.pku.edu.cn" target="_blank" rel="noopener">
          <span>Peking University</span>
          </a>
        </h3>
        
      </div>

      <ul class="network-icon" aria-hidden="true">
        
        
        
        
          
        
        
        
        
        
          
        
        <li>
          <a href="https://jianzhang.tech" target="_blank" rel="noopener">
            <i class="fas fa-home big-icon"></i>
          </a>
        </li>
        
        
        
        
          
        
        
        
        
        
        <li>
          <a href="mailto:%20%20zhangjian.sz@pku.edu.cn" >
            <i class="fas fa-envelope big-icon"></i>
          </a>
        </li>
        
        
        
        
        
        
        
        
          
        
        <li>
          <a href="https://scholar.google.com/citations?user=7brFI_4AAAAJ&amp;hl=en" target="_blank" rel="noopener">
            <i class="ai ai-google-scholar big-icon"></i>
          </a>
        </li>
        
        
        
        
          
        
        
        
        
        
          
        
        <li>
          <a href="https://github.com/jianzhangcs" target="_blank" rel="noopener">
            <i class="fab fa-github big-icon"></i>
          </a>
        </li>
        
      </ul>

    </div>
  </div>
  <div class="col-12 col-lg-8">

    
    

    <p>Dr. Jian Zhang is an Assistant Professor (Ph.D. Supervisor) at
the School of Electronic and Computer Engineering (SECE),
Shenzhen Graduate School, Peking University, Shenzhen, China.
He is now leading the

<a href="https://villa.jianzhang.tech" target="_blank" rel="noopener"><b style="color: #00ff00;">V</b>isual-Information <b style="color: #FF9900;">I</b>ntelligent <b style="color: #3333CC;">L</b>earning <b style="color: #006600;">L</b><b style="color: #FF0000">A</b>B (<b style="color: #00ff00;">V</b><b style="color: #FF9900;">I</b><b style="color: #3333CC;">L</b><b style="color: #006600;">L</b><b style="color: #FF0000;">A</b>).</a></p>
<p>He received the B.S. degree from the Department of Mathematics,
Harbin Institute of Technology (HIT), Harbin, China, in 2007, and received his
M.Eng. and Ph.D. degrees (under the supervision of Prof. Debin Zhao) from the
School of Computer Science and Technology, HIT, in 2009 and 2014, respectively.
From 2014 to 2018, he worked as a postdoctoral researcher at
Peking University (PKU) (cooperated with Prof. Wen Gao) and
King Abdullah University of Science and Technology (KAUST)
(cooperated with Prof. Bernard Ghanem).</p>
<p>His research interest focuses on intelligent multimedia processing, including low-level vision, AI-generated content (AIGC) and security. He has published over 100 technical articles in refereed international journals and proceedings, with more than 7060 citations 
<a href="https://scholar.google.com/citations?user=7brFI_4AAAAJ&amp;hl=en" target="_blank" rel="noopener">[Google Scholar].</a>
In teaching, he won the first prize in the 23rd Young Teachers&rsquo; Teaching Basic Skills Competition at Peking University (as well as the best teaching demonstration prize and the most popular prize among students), the honorary title of &ldquo;Excellent Class Teacher&rdquo; at Peking University. In research, he won the 2011 Best Paper Award of IEEE International Conference on Visual Communication and Image Processing (VCIP), the 2015 Best Student Paper Award of the International Conference, the 2018 Best Paper Award of IEEE MultiMedia, and the ChinaMM 2021 Best Paper Award, Shenzhen Science and Technology Association, won the 2021 Excellent Natural Science Academic Paper Award (16 in total, the only one in the information field) and the 2023 China Artificial Intelligence Society-Huawei MindSpore Academic Award Fund Project Excellence Award. With ByteDance, he won the &ldquo;NTIRE 2023 Global Challenge Panoramic Image Super-resolution Track&rdquo; championship and was selected as the &ldquo;Top 2% Scientists in the World&rdquo; list by Stanford University for four consecutive years. In service, he is the director of the Youth Working Committee of Shenzhen Artificial Intelligence Society, the director of Guangdong Image and Graphics Society, the member of the Youth Working Committee of China Image and Graphics Society, and the executive member of the Seminar for Young Scholars in Vision and Learning (VALSE). At the same time, he serves on the editorial board of international journals such as Journal of Visual Communication and Image Representation, Signal, Image and Video Processing, CAAI Transactions on Intelligence Technology, etc.</p>
<p>The representative works mainly include: 1) GSR puts forward the sparse representation model and theory of image structure groups, which broke through the limitation that the previous block sparse representation model was only partially dependent, and was selected as a highly cited paper of ESI, with more than 740 citations, and was rated as one of the representative works based on sparse representation in the field of image reconstruction by many experts and scholars; 2) ISTA-Net puts forward the theory of using structured deep neural network to solve the optimization reconstruction problem, and designs a deep unfolding network inspired by iterative soft threshold algorithm, which is both interpretable and structural, greatly improving the efficiency and performance of image reconstruction, and has become the most representative work in this field, with more than 1020 citations; 3) The representative work 
<a href="https://github.com/TencentARC/T2I-Adapter" target="_blank" rel="noopener">T2I-Adapter</a> won more than 2500 stars on GitHub less than half a year after its launch and has been combined by Stability AI, a unicorn company in the AIGC field, with its flagship model StableDiffusionXL, and used in the graffiti generation product 
<a href="https://stability.ai/blog/clipdrop-launches-stable-doodle" target="_blank" rel="noopener">Stable Doodle</a>. In cooperation with Hugging Face, T2I-Adapter-SDXL was jointly developed and launched in the community.</p>
<p>张健，北京大学深圳研究生院信息工程学院助理教授/研究员、博士生导师，视觉信息智能学习实验室（VILLA）负责人，深圳市海外高层次人才。分别于2007年、2009年、2014年获得哈尔滨工业大学（HIT）数学与应用数学理学学士、计算机科学与技术工学硕士及计算机应用工学博士（导师：赵德斌教授）。2014-2018年期间先后在北京大学(PKU)（合作导师：高文院士）和沙特国王科技大学(KAUST)（合作导师：Bernard Ghanem教授，AI中心主任）做博士后访问研究。</p>
<p>主要从事基于AI的图像重建与生成，包括底层视觉与计算成像、AI内容生成（AIGC）与安全等，共计发表包括TPAMI、IJCV、TIP、CVPR、ECCV、ICCV、NeurIPS、ICLR等高水平权威国际期刊/会议论文100余篇，其中以第一/通讯作者在ACM/IEEE汇刊和CCF-A类期刊/会议上发表论文60余篇，个人Google Scholar引用7065次（其中单篇一作会议和期刊论文最高引用分别为1020次和749次），h-index值为41。入职北京大学后，于2019年创立了视觉信息智能学习实验室（VILLA）。近两年，带领VILLA以第一或通讯作者在CCF-A类会议/期刊上发表论文20余篇。相关研究成果申请/授权中国专利10余项。主持国家自然科学基金青年科学基金项目、国家自然科学基金面上项目、国家自然科学基金重点项目子课题、深圳市科技攻关项目子课题以及与字节/华为/OPPO/腾讯/创维/兔展等知名企业学术合作项目共10余项。</p>
<p>教学方面，获得北京大学第二十三届青年教师教学基本功比赛一等奖（以及最佳教学演示奖和最受学生欢迎奖）、北京大学“优秀班主任”、北京大学“优秀共产党员”荣誉称号等；科研方面，获得IEEE视觉通讯与图像处理（VCIP）国际会议2011年度最佳论文奖以及该国际会议2015年度最佳学生论文奖、IEEE多媒体IEEE MultiMedia国际期刊2018年度最佳论文奖、中国多媒体大会ChinaMM 2021年度最佳论文奖、深圳市科学技术协会2021年优秀自然科学学术论文奖（共16篇，信息领域唯一1篇）、2023中国人工智能学会—华为MindSpore学术奖励基金项目优秀奖，携手字节获“NTIRE 2023全球挑战赛全景图像超分辨率赛道”总冠军、连续四年入选斯坦福大学评选“全球前2%顶尖科学家”榜单等。
服务方面，担任深圳市人工智能学会青年工作委员会主任、广东省图象图形学会理事、中国图象图形学学会青年工作委员会委员、视觉与学习青年学者研讨会（VALSE）执行委员等；同时担任Journal of Visual Communication and Image Representation、Signal, Image and Video Processing、CAAI Transactions on Intelligence Technology等国际期刊编委。</p>
<p>代表工作主要有：1）GSR提出了图像结构组稀疏表示模型与理论，突破了前期块稀疏表示模型仅局部依赖的限制，入选ESI高被引论文，单篇引用超过740次，被多位专家学者评为图像重建领域基于稀疏表示的代表性工作之一；2）ISTA-Net提出利用结构化深度神经网络求解优化重建问题理论，设计迭代软阈值算法启发的深度展开网络，兼具可解释性和结构性，大幅提升图像重建效率和性能，已成为该领域最具代表性工作，单篇引用超过1020次；3）T2I-Adapter推出不到半年在GitHub获超过2500 stars,已被AIGC领域独角兽公司Stability AI与其旗舰模型StableDiffusionXL结合，用于涂鸦生成产品 Stable Doodle 中，服务全球用户；团队与Hugging Face公司合作开发推出了 T2I-Adapter-SDXL 在社区上线。</p>
<p>欢迎优秀的本科生和硕士生保送和报考北京大学信息工程学院的硕士和博士研究生，课题组博士后职位也已开放，更多最新信息请查看个人学术主页：
<a href="https://jianzhang.tech/" target="_blank" rel="noopener">https://jianzhang.tech/</a> 或者信息工程学院教师
<a href="https://www.ece.pku.edu.cn/info/1046/2506.htm" target="_blank" rel="noopener">[中文主页]</a>以及实验室主页：
<a href="https://villa.jianzhang.tech/" target="_blank" rel="noopener">https://villa.jianzhang.tech/</a> 。</p>


    <div class="row">

      
      <div class="col-md-5">
        <h3>Research Areas</h3>
        <ul class="ul-interests">
          
          <li>AI-based low-level vision and computational imaging</li>
          
          <li>AI-generated content (AIGC) and security</li>
          
        </ul>
      </div>
      

      

    </div>

    <div class="row">

      
      <div class="col-md-5">
        <h3>Awards</h3>
        <ul class="ul-interests">
          
          <li>Selected in the list of “Single Year Impact” of the top 2% scientists in the world in 2020</li>
          
          <li>Best Paper Award (IEEE MultiMedia) 2018</li>
          
          <li><a href="https://jianzhang.tech/img/VCIP2015_BestStudentPaperAward.jpg">Best Student Paper Award at IEEE Visual Communications and Image Processing (VCIP) 2015</a></li>
          
          <li>Excellent Ph.D. Thesis Award, Harbin Section, ACM China 2015</li>
          
          <li>Excellent Ph.D. Thesis Award, Harbin Institute of Technology 2015</li>
          
          <li>Best Student Paper Award in School of Computer Science and Technology (HIT) 2013</li>
          
          <li>National Scholarship, Harbin Institute of Technology (HIT) 2012</li>
          
          <li>Outstanding Individual Award in NELVT (2012)</li>
          
          <li>Best Student Paper Award in School of Computer Science and Technology (HIT) 2012</li>
          
          <li>First Prize of Qualcomm Innovation Fellowship (QInF) 2012</li>
          
          <li>Outstanding Individual Award in NELVT (2011)</li>
          
          <li><a href="https://jianzhang.tech/img/VCIP2011_BestPaperAward.jpg">Best Paper Award at IEEE Visual Communications and Image Processing (VCIP) 2011</a></li>
          
        </ul>
      </div>
      

      
    </div>

  </div>
</div>

    

    
    
    
    <div class="article-widget content-widget-hr">
      <h3>Publication</h3>
      <ul>
        
        <li>
          <a href="/publication/100084/">360DVD: Controllable Panorama Video Generation with 360-Degree Video Diffusion Model</a>
        </li>
        
        <li>
          <a href="/publication/100083/">DiffEditor: Boosting Accuracy and Flexibility on Diffusion-based Image Editing</a>
        </li>
        
        <li>
          <a href="/publication/100085/">EditGuard: Versatile Image Watermarking for Tamper Localization and Copyright Protection</a>
        </li>
        
        <li>
          <a href="/publication/100078/">DragonDiffusion: Enabling Drag-style Manipulation on Diffusion Models</a>
        </li>
        
        <li>
          <a href="/publication/100079/">Progressive3D: Progressively Local Editing for Text-to-3D Content Creation with Complex Semantic Prompts</a>
        </li>
        
        <li>
          <a href="/publication/100077/">Optical Flow for Spike Camera with Hierarchical Spatial-Temporal Spike Fusion</a>
        </li>
        
        <li>
          <a href="/publication/100076/">Joint Demosaicing and Denoising for Spike Camera</a>
        </li>
        
        <li>
          <a href="/publication/200052/">Faster Person Re-Identification: One-shot-Filter and Coarseto-Fine Search</a>
        </li>
        
        <li>
          <a href="/publication/100074/">T2i-adapter: Learning adapters to dig out more controllable ability for text-to-image diffusion models</a>
        </li>
        
        <li>
          <a href="/publication/200051/">Deep Unfolding Network for Image Compressed Sensing by Content-adaptive Gradient Updating and Deformation-invariant Non-local Modeling</a>
        </li>
        
        <li>
          <a href="/publication/100073/">CRoSS: Diffusion Model Makes Controllable, Robust and Secure Image Steganography</a>
        </li>
        
        <li>
          <a href="/publication/200050/">SODAS-Net: Side-Information-Aided Deep Adaptive Shrinkage Network for Compressive Sensing</a>
        </li>
        
        <li>
          <a href="/publication/100071/">A Unified Continual Learning Framework with General Parameter-Efficient Tuning</a>
        </li>
        
        <li>
          <a href="/publication/100070/">Freedom: Training-free energy-guided conditional diffusion model</a>
        </li>
        
        <li>
          <a href="/publication/100072/">Implicit Neural Representation for Cooperative Low-light Image Enhancement</a>
        </li>
        
        <li>
          <a href="/publication/200048/">Deep Physics-Guided Unrolling Generalization for Compressed Sensing</a>
        </li>
        
        <li>
          <a href="/publication/200049/">CSformer: Bridging Convolution and Transformer for Compressive Sensing</a>
        </li>
        
        <li>
          <a href="/publication/100069/">Null-Space Diffusion Sampling for Zero-Shot Point Cloud Completion</a>
        </li>
        
        <li>
          <a href="/publication/200047/">Semantic-aware Visual Decomposition for Image Coding</a>
        </li>
        
        <li>
          <a href="/publication/200046/">An Object SLAM Framework for Association, Mapping, and High-Level Tasks</a>
        </li>
        
        <li>
          <a href="/publication/200045/">Dynamic Path-Controllable Deep Unfolding Network for Compressive Sensing</a>
        </li>
        
        <li>
          <a href="/publication/100065/">EDA: Explicit Text-Decoupling and Dense Alignment for 3D Visual Grounding</a>
        </li>
        
        <li>
          <a href="/publication/100066/">Large-capacity and Flexible Video Steganography via Invertible Neural Network</a>
        </li>
        
        <li>
          <a href="/publication/100068/">Optimization-Inspired Cross-Attention Transformer for Compressive Sensing</a>
        </li>
        
        <li>
          <a href="/publication/100067/">Panoptic Compositional Feature Field for Editable Scene Rendering with Network-Inferred Labels via Metric Learning</a>
        </li>
        
        <li>
          <a href="/publication/200044/">DEAR-GAN: Degradation-Aware Face Restoration with GAN Prior</a>
        </li>
        
        <li>
          <a href="/publication/200043/">Deep Memory-Augmented Proximal Unrolling Network for Compressive Sensing</a>
        </li>
        
        <li>
          <a href="/publication/100064/">Zero-Shot Image Restoration Using Denoising Diffusion Null-Space Model</a>
        </li>
        
        <li>
          <a href="/publication/100062/">GAN Prior based Null-Space Learning for Consistent Super-Resolution</a>
        </li>
        
        <li>
          <a href="/publication/100060/">HVTSurv: Hierarchical Vision Transformer for Patient-level Survival Prediction from Whole Slide Image</a>
        </li>
        
        <li>
          <a href="/publication/100061/">Learning to Super-Resolve Dynamic Scenes for Neuromorphic Spike Camera</a>
        </li>
        
        <li>
          <a href="/publication/100063/">Less Is More Important: An Attention Module Guided by Probability Density Function for Convolutional Neural Networks</a>
        </li>
        
        <li>
          <a href="/publication/200042/">Physics-Inspired Compressive Sensing: Beyond Deep Unrolling</a>
        </li>
        
        <li>
          <a href="/publication/200041/">Contrastive Unfolding Deraining Network</a>
        </li>
        
        <li>
          <a href="/publication/200040/">TransCL: Transformer Makes Strong and Flexible Compressive Learning</a>
        </li>
        
        <li>
          <a href="/publication/200038/">Content-aware Scalable Deep Compressed Sensing</a>
        </li>
        
        <li>
          <a href="/publication/200039/">Hierarchical Similarity Learning for Aliasing Suppression Image Super-Resolution</a>
        </li>
        
        <li>
          <a href="/publication/100059/">Metric Learning based Interactive Modulation for Real-World Super-Resolution</a>
        </li>
        
        <li>
          <a href="/publication/100058/">R-DFCIL: Relation-Guided Representation Learning for Data-Free Class Incremental Learning</a>
        </li>
        
        <li>
          <a href="/publication/100056/">Consistency-Contrast Learning for Conceptual Coding</a>
        </li>
        
        <li>
          <a href="/publication/100055/">More is better: Multi-source Dynamic Parsing Attention for Occluded Person Re-identification</a>
        </li>
        
        <li>
          <a href="/publication/100057/">Multiple Instance Learning with Mixed Supervision in Gleason Grading</a>
        </li>
        
        <li>
          <a href="/publication/100054/">Semantic Neural Rendering-based Video Coding: Towards Ultra-Low Bitrate Video Conferencing</a>
        </li>
        
        <li>
          <a href="/publication/200037/">A Simple Visual-Textual Baseline for Pedestrian Attribute Recognition</a>
        </li>
        
        <li>
          <a href="/publication/200036/">DREAMT: Diversity Enlarged Mutual Teaching for Unsupervised Domain Adaptive Person Re-Identiﬁcation</a>
        </li>
        
        <li>
          <a href="/publication/200035/">High-Throughput Deep Unfolding Network for Compressive Sensing MRI</a>
        </li>
        
        <li>
          <a href="/publication/200034/">PUERT: Probabilistic Under-sampling and Explicable Reconstruction Network for CS-MRI</a>
        </li>
        
        <li>
          <a href="/publication/200033/">Conceptual Compression via Deep Structure and Texture Synthesis</a>
        </li>
        
        <li>
          <a href="/publication/100051/">Deep Generalized Unfolding Networks for Image Restoration</a>
        </li>
        
        <li>
          <a href="/publication/100053/">HerosNet: Hyperspectral Explicable Reconstruction and Optimal Sampling Deep Network for Snapshot Compressive Imaging</a>
        </li>
        
        <li>
          <a href="/publication/100052/">Robust Invertible Image Steganography</a>
        </li>
        
        <li>
          <a href="/publication/200032/">Learning Disentangled Representation Implicitly via Transformer for Occluded Person Re-Identification</a>
        </li>
        
        <li>
          <a href="/publication/100049/">Panini-Net: GAN Prior based Degradation-Aware Feature Interpolation for Face Restoration</a>
        </li>
        
        <li>
          <a href="/publication/100050/">Unpaired Multi-Domain Stain Transfer for Kidney Histopathological Images</a>
        </li>
        
        <li>
          <a href="/publication/100048/">TransMIL: Transformer based Correlated Multiple Instance Learning for Whole Slide Image Classification</a>
        </li>
        
        <li>
          <a href="/publication/100046/">Dense Deep Unfolding Network with 3D-CNN Prior for Snapshot Compressive Sensing</a>
        </li>
        
        <li>
          <a href="/publication/100045/">Dynamic Attentive Graph Learning for Image Restoration</a>
        </li>
        
        <li>
          <a href="/publication/100047/">Super Resolve Dynamic Scene from Continuous Spike Streams</a>
        </li>
        
        <li>
          <a href="/publication/100044/">Memory-Augmented Deep Unfolding Network for Compressive Sensing</a>
        </li>
        
        <li>
          <a href="/publication/100043/">Expressive and Compressive GAN Inversion Network</a>
        </li>
        
        <li>
          <a href="/publication/100042/">Dynamic Multi-Domain Translation Network For Single Image Deraining</a>
        </li>
        
        <li>
          <a href="/publication/200030/">COAST: COntrollable Arbitrary-Sampling NeTwork for Compressive Sensing</a>
        </li>
        
        <li>
          <a href="/publication/200029/">CAS: Correlation Adaptive Sparse Modeling for Image Denoising</a>
        </li>
        
        <li>
          <a href="/publication/200028/">Iterative Network for Image Super-Resolution</a>
        </li>
        
        <li>
          <a href="/publication/100040/">Graph Attention Neural Network for Image Restoration</a>
        </li>
        
        <li>
          <a href="/publication/100041/">Spatial-temporal Synergic Prior Driven Unfolding Network for Snapshot Compressive Imaging</a>
        </li>
        
        <li>
          <a href="/publication/100039/">Synergic Feature Attention for Image Restoration</a>
        </li>
        
        <li>
          <a href="/publication/100034/">Invertible Resampling-Based Layered Image Compression</a>
        </li>
        
        <li>
          <a href="/publication/100033/">ISTA-Net&#43;&#43;: Flexible Deep Unfolding Network for Compressive Sensing</a>
        </li>
        
        <li>
          <a href="/publication/100037/">Spk2ImgNet:Learning to Reconstruct Dynamic Scene from Continuous Spike Stream</a>
        </li>
        
        <li>
          <a href="/publication/100036/">Thousand to One: Semantic Prior Modeling for Conceptual Coding</a>
        </li>
        
        <li>
          <a href="/publication/200027/">COLA-Net: Collaborative Attention Network for Image Restoration</a>
        </li>
        
        <li>
          <a href="/publication/100032/">Matching on Sets: Conquer Occluded Person Re-Identification Without Alignment</a>
        </li>
        
        <li>
          <a href="/publication/100001/">A Similarity Inference Metric for RGB-Infrared Cross-Modality Person Re-identification</a>
        </li>
        
        <li>
          <a href="/publication/200002/">End-to-end Learned, Optically Coded Super-resolution SPAD Camera</a>
        </li>
        
        <li>
          <a href="/publication/200001/">Optimization-Inspired Compact Deep Compressive Sensing</a>
        </li>
        
        <li>
          <a href="/publication/100002/">A Novel Two-stage Separable Deep Learning Framework for Practical Blind Watermarking</a>
        </li>
        
        <li>
          <a href="/publication/200009/">Collaborative Representation Cascade for Single-Image Super-Resolution</a>
        </li>
        
        <li>
          <a href="/publication/200003/">Divisively Normalized Sparse Coding: Toward Perceptual Visual Signal Representation</a>
        </li>
        
        <li>
          <a href="/publication/200007/">Globally Variance-Constrained Sparse Representation and Its Application in Image Set Coding</a>
        </li>
        
        <li>
          <a href="/publication/100003/">ISTA-Net: Interpretable Optimization-Inspired Deep Network for Image Compressive Sensing</a>
        </li>
        
        <li>
          <a href="/publication/200005/">Probabilistic Decision Based Block Partitioning for Future Video Coding</a>
        </li>
        
        <li>
          <a href="/publication/200006/">Structure-aware Local Sparse Coding for Visual Tracking</a>
        </li>
        
        <li>
          <a href="/publication/200013/">Adaptive Progressive Motion Vector Resolution Selection Based on Rate-Distortion Optimization</a>
        </li>
        
        <li>
          <a href="/publication/100004/">Effective Quadtree Plus Binary Tree Block Partition Decision for Future Video Coding</a>
        </li>
        
        <li>
          <a href="/publication/200017/">Entropy of Primitive: From Sparse Representation to Visual Information Evaluation</a>
        </li>
        
        <li>
          <a href="/publication/200008/">Fourier Ptychographic Microscopy with Sparse Representation</a>
        </li>
        
        <li>
          <a href="/publication/100005/">Globally Variance-Constrained Sparse Representation for Rate-Distortion Optimized Image Representation</a>
        </li>
        
        <li>
          <a href="/publication/200015/">Low-Rank-Based Nonlocal Adaptive Loop Filter for High-Efficiency Video Compression</a>
        </li>
        
        <li>
          <a href="/publication/200010/">Power Distortion Optimization for Uncoded Linear Transformed Transmission of Images and Videos</a>
        </li>
        
        <li>
          <a href="/publication/200011/">Reducing Image Compression Artifacts by Structural Sparse Representation and Quantization Constraint Prior</a>
        </li>
        
        <li>
          <a href="/publication/200016/">Utility-Driven Adaptive Preprocessing for Screen Content Video Compression</a>
        </li>
        
        <li>
          <a href="/publication/200012/">Video Compressive Sensing Reconstruction Via Reweighted Residual Sparsity</a>
        </li>
        
        <li>
          <a href="/publication/100009/">Adaptive Motion Vector Resolution Scheme for Enhanced Video Coding</a>
        </li>
        
        <li>
          <a href="/publication/200019/">CCR: Clustering and Collaborative Representation for Fast Single Image Super-Resolution</a>
        </li>
        
        <li>
          <a href="/publication/100008/">Compressive-Sensed Image Coding via Stripe-based DPCM</a>
        </li>
        
        <li>
          <a href="/publication/200020/">CONCOLOR: Constrained Non-Convex Low-Rank Model for Image Deblocking</a>
        </li>
        
        <li>
          <a href="/publication/200014/">Image Denoising via Bandwise Adaptive Modeling and Regularization Exploiting Nonlocal Similarity</a>
        </li>
        
        <li>
          <a href="/publication/100007/">Nonconvex Lp Nuclear Norm based ADMM Framework for Compressed Sensing</a>
        </li>
        
        <li>
          <a href="/publication/200018/">Nonlocal In-Loop Filter: The Way Toward Next-Generation Video Coding?</a>
        </li>
        
        <li>
          <a href="/publication/100006/">Structure-driven Adaptive Non-local Filter for High Efficiency Video Coding (HEVC)</a>
        </li>
        
        <li>
          <a href="/publication/100011/">Adaptive Local Nonparametric Regression for Fast Single Image Super-Resolution</a>
        </li>
        
        <li>
          <a href="/publication/100017/">Block-Based Compressive Sensing Coding of Natural Images by Local Structural Measurement Matrix</a>
        </li>
        
        <li>
          <a href="/publication/100016/">Image Denoising via Adaptive Soft-Thresholding Based on Non-Local Samples</a>
        </li>
        
        <li>
          <a href="/publication/200021/">Group-Based Sparse Representation for Image Restoration</a>
        </li>
        
        <li>
          <a href="/publication/200023/">Image Compressive Sensing Recovery Using Adaptively Learned Sparsifying Basis via L0 Minimization</a>
        </li>
        
        <li>
          <a href="/publication/200022/">Image Restoration Using Joint Statistical Modeling in a Space-Transform Domain</a>
        </li>
        
        <li>
          <a href="/publication/100022/">Improved Total Variation based Image Compressive Sensing Recovery by Nonlocal Regularization</a>
        </li>
        
        <li>
          <a href="/publication/100021/">Structural Group Sparse Representation for Image Compressive Sensing Recovery</a>
        </li>
        
        <li>
          <a href="/publication/100024/">Compressed Sensing Recovery via Collaborative Sparsity</a>
        </li>
        
        <li>
          <a href="/publication/100026/">Exploiting Image Local and Nonlocal Consistency for Mixed Gaussian-Impulse Noise Removal</a>
        </li>
        
        <li>
          <a href="/publication/200025/">Image Compressive Sensing Recovery via Collaborative Sparsity</a>
        </li>
        
        <li>
          <a href="/publication/100027/">Image Primitive Coding and Visual Quality Assessment</a>
        </li>
        
        <li>
          <a href="/publication/100025/">Image Super-Resolution via Dual-Dictionary Learning and Sparse Representation</a>
        </li>
        
        <li>
          <a href="/publication/100029/">High-Quality Image Restoration from Partial Random Samples in Spatial Domain</a>
        </li>
        
        <li>
          <a href="/publication/200026/">Interpolation-Dependent Image Downsampling</a>
        </li>
        
      </ul>
    </div>
    
  </div>
</section>

      

    
    
    
      <script src="https://cdn.bootcdn.net/ajax/libs/jquery/3.5.1/jquery.min.js" integrity="sha256-9/aliU8dGd2tb6OSsuzixeV4y/faTqgFtohetphbbj0=" crossorigin="anonymous"></script>
      <script src="https://cdn.bootcdn.net/ajax/libs/jquery.imagesloaded/4.1.4/imagesloaded.pkgd.min.js" integrity="sha256-lqvxZrPLtfffUl2G/e7szqSvPBILGbwmsGE1MKlOi0Q=" crossorigin="anonymous"></script>
      <script src="https://cdn.bootcdn.net/ajax/libs/jquery.isotope/3.0.6/isotope.pkgd.min.js" integrity="sha256-CBrpuqrMhXwcLLUd5tvQ4euBHCdh7wGlDfNz8vbu/iI=" crossorigin="anonymous"></script>
      <script src="https://cdn.bootcdn.net/ajax/libs/fancybox/3.5.7/jquery.fancybox.min.js" integrity="sha256-yt2kYMy0w8AbtF89WXb2P1rfjcP/HTHLT7097U8Y5b8=" crossorigin="anonymous"></script>
      <script src="https://cdn.bootcdn.net/ajax/libs/instant.page/5.1.0/instantpage.min.js" integrity="sha512-1+qUtKoh9XZW7j+6LhRMAyOrgSQKenQ4mluTR+cvxXjP1Z54RxZuzstR/H9kgPXQsVB8IW7DMDFUJpzLjvhGSQ==" crossorigin="anonymous"></script>

      

      
        
        <script src="https://cdn.bootcdn.net/ajax/libs/highlight.js/10.1.2/highlight.min.js" integrity="sha512-7t8APmYpzEsZP7CYoA7RfMPV9Bb+PJHa9x2WiUnDXZx3XHveuyWUtvNOexhkierl5flZ3tr92dP1mMS+SGlD+A==" crossorigin="anonymous"></script>
        
        <script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/10.1.2/languages/r.min.js"></script>
        
      

    

    
    
      <script src="https://cdn.bootcdn.net/ajax/libs/leaflet/1.5.1/leaflet.js" integrity="sha256-EErZamuLefUnbMBQbsEqu1USa+btR2oIlCpBJbyD4/g=" crossorigin="anonymous"></script>
    

    
    
    <script>const code_highlighting = true;</script>
    

    

    
    

    

    
    

    
    

    
    

    
    

    
    

    
    
    
    
    
    
    
    
    
    
    
    
    <script src="/js/academic.min.ba49144ee7dfc686873104eea3c4dca2.js"></script>

    






  
  
  <div class="container">
    <footer class="site-footer">
  

  <p class="powered-by">
    Copyright © <code>2024</code> VILLA · Peking University | Powered by <a href='https://wowchemy.com/' target='_blank'>Wowchemy</a> | <a href='https://beian.miit.gov.cn' target='_blank'>粤ICP备2021179063号</a>
  </p>

  
  






  <p class="powered-by">
    

    
    <span class="float-right" aria-hidden="true">
      <a href="#" class="back-to-top">
        <span class="button_icon">
          <i class="fas fa-chevron-up fa-2x"></i>
        </span>
      </a>
    </span>
    
  </p>
</footer>

  </div>
  

  
<div id="modal" class="modal fade" role="dialog">
  <div class="modal-dialog">
    <div class="modal-content">
      <div class="modal-header">
        <h5 class="modal-title">Cite</h5>
        <button type="button" class="close" data-dismiss="modal" aria-label="Close">
          <span aria-hidden="true">&times;</span>
        </button>
      </div>
      <div class="modal-body">
        <pre><code class="tex hljs"></code></pre>
      </div>
      <div class="modal-footer">
        <a class="btn btn-outline-primary my-1 js-copy-cite" href="#" target="_blank">
          <i class="fas fa-copy"></i> Copy
        </a>
        <a class="btn btn-outline-primary my-1 js-download-cite" href="#" target="_blank">
          <i class="fas fa-download"></i> Download
        </a>
        <div id="modal-error"></div>
      </div>
    </div>
  </div>
</div>

</body>
</html>
